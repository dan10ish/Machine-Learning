{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoztdpd2jWfAunJOaknRIK"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wXNqgRUOejR",
        "outputId": "63018a8f-5330-4afd-8002-bc7a60afe652"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#Class for Stopping at 95% accuracy\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "  def on_epoch_end(self, epoch,logs={}):\n",
        "    if(logs.get('accuracy')>0.95): \n",
        "      print(\"\\nReached 95% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "#Loading TensorFlow Dataset\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "#Accessing Data\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "#Normalizing\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    #Input layer                                \n",
        "    tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
        "\n",
        "    #Hidden Layer\n",
        "    tf.keras.layers.Dense(128, activation=(tf.nn.relu)),\n",
        "\n",
        "    #Output layer\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "\n",
        "])\n",
        "\n",
        "#Loss function and Optimizer\n",
        "model.compile(optimizer = 'adam', \n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=50, callbacks=[callbacks])\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4998 - accuracy: 0.8239\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3770 - accuracy: 0.8640\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3359 - accuracy: 0.8768\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3143 - accuracy: 0.8852\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2954 - accuracy: 0.8905\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2814 - accuracy: 0.8951\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2683 - accuracy: 0.9006\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2593 - accuracy: 0.9048\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2481 - accuracy: 0.9076\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2408 - accuracy: 0.9099\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2312 - accuracy: 0.9131\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2245 - accuracy: 0.9165\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2167 - accuracy: 0.9191\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2105 - accuracy: 0.9203\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2056 - accuracy: 0.9227\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1992 - accuracy: 0.9255\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1929 - accuracy: 0.9282\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1897 - accuracy: 0.9289\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1822 - accuracy: 0.9309\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1792 - accuracy: 0.9323\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1734 - accuracy: 0.9352\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1698 - accuracy: 0.9351\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1645 - accuracy: 0.9380\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1618 - accuracy: 0.9384\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1585 - accuracy: 0.9408\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1554 - accuracy: 0.9415\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1515 - accuracy: 0.9431\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1506 - accuracy: 0.9436\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1448 - accuracy: 0.9447\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1429 - accuracy: 0.9463\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1388 - accuracy: 0.9474\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1375 - accuracy: 0.9486\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1324 - accuracy: 0.9504\n",
            "\n",
            "Reached 95% accuracy so cancelling training!\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.4311 - accuracy: 0.8842\n",
            "[2.3850981e-13 1.2538194e-14 2.7371167e-17 1.2438264e-19 2.4923074e-16\n",
            " 9.4424692e-08 4.5858210e-16 5.3242466e-04 1.6504095e-12 9.9946755e-01]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}